{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7d73939",
   "metadata": {},
   "source": [
    "# 1. 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8052f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"나는 오늘 기분이 좋다\",\n",
    "    \"오늘 날씨가 좋다\",\n",
    "    \"나는 기분이 나쁘다\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdecb33",
   "metadata": {},
   "source": [
    "## 1) 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd032b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나는 오늘 기분이 좋다\n",
      "오늘 날씨가 좋다\n",
      "나는 기분이 나쁘다\n",
      "['나는', '오늘', '기분이', '좋다', '오늘', '날씨가', '좋다', '나는', '기분이', '나쁘다']\n"
     ]
    }
   ],
   "source": [
    "# sentences ->단어 집합\n",
    "word_list = []\n",
    "for sent in sentences:\n",
    "    # STEP1. 문장을 스페이스기준으로 쪼갠다.\n",
    "    words = sent.split()\n",
    "    print(sent)\n",
    "    # STEP2. 쪼갠 단어들을 word_list에포함시킨다.\n",
    "    word_list.extend(words) \n",
    "print(word_list)\n",
    "\n",
    "word_set = set(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0be3b3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 4 1 5 2]\n",
      "['기분이' '나는' '나쁘다' '날씨가' '오늘' '좋다']\n"
     ]
    }
   ],
   "source": [
    "# 단어를 아무 의미 없이 단순히 숫자 매칭\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lavel_encoder = LabelEncoder()\n",
    "encoded = lavel_encoder.fit_transform(list(word_set)) # 단어리스트 : 단어의 집합\n",
    "print(encoded)\n",
    "print(lavel_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2ea690a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 기분이\n",
      "0 나는\n",
      "4 나쁘다\n",
      "1 날씨가\n",
      "5 오늘\n",
      "2 좋다\n",
      "{np.str_('기분이'): np.int64(3), np.str_('나는'): np.int64(0), np.str_('나쁘다'): np.int64(4), np.str_('날씨가'): np.int64(1), np.str_('오늘'): np.int64(5), np.str_('좋다'): np.int64(2)}\n"
     ]
    }
   ],
   "source": [
    "# 딕셔너리 {단어:인덱스},{인덱스:단어}\n",
    "label_dic={}\n",
    "for idx,word in zip(encoded,lavel_encoder.classes_):\n",
    "    print(idx,word)\n",
    "    label_dic[word] = idx\n",
    "print(label_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413b1965",
   "metadata": {},
   "source": [
    "## 2)원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0082e705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['날씨가' '기분이' '오늘' '나는' '좋다' '좋다.' '나쁘다']\n",
      "[['날씨가']\n",
      " ['기분이']\n",
      " ['오늘']\n",
      " ['나는']\n",
      " ['좋다']\n",
      " ['좋다.']\n",
      " ['나쁘다']]\n"
     ]
    }
   ],
   "source": [
    "# 단어를 0과 1로 이루어진 벡터로 표현\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# STEP1. 단어 집합을 배열로 바꾼다.\n",
    "word_arr = np.array(list(word_set))\n",
    "print(word_arr)\n",
    "\n",
    "#S STEP2. reshape를 통해 배열 형태를 바꾼다.\n",
    "word_arr_reshape = word_arr.reshape(-1,1) # 행은 몇개가 될지는 모르지만, 열을 1로 맞춘다.\n",
    "print(word_arr_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c7d9d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 7 stored elements and shape (7, 7)>\n",
      "  Coords\tValues\n",
      "  (0, 3)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (2, 4)\t1.0\n",
      "  (3, 1)\t1.0\n",
      "  (4, 5)\t1.0\n",
      "  (5, 6)\t1.0\n",
      "  (6, 2)\t1.0\n",
      "[[0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "oh_encoder = OneHotEncoder()\n",
    "endoded = oh_encoder.fit_transform(word_arr_reshape)\n",
    "print(endoded)\n",
    "print(endoded.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78128382",
   "metadata": {},
   "source": [
    "# 2. 벡터라이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "320c88f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"나는 좋다 오늘 기분이 좋다\",\n",
    "    \"오늘 날씨가 좋다\",\n",
    "    \"나는 기분이 나쁘다\",\n",
    "    \"집에 가고 싶다 집 좋다\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef01c55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나는', '좋다', '오늘', '기분이', '좋다', '오늘', '날씨가', '좋다', '나는', '기분이', '나쁘다']\n"
     ]
    }
   ],
   "source": [
    "# 단어 리스트 만들기\n",
    "word_list = []\n",
    "for sent in sentences : \n",
    "    word_list.extend(sent.split())\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c2f9042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'좋다': 3, '나는': 2, '오늘': 2, '기분이': 2, '날씨가': 1, '나쁘다': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter(word_list)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d5112f",
   "metadata": {},
   "source": [
    "## 1) CountVectorizere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d57b659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나는 좋다 오늘 기분이 좋다', '오늘 날씨가 좋다', '나는 기분이 나쁘다']\n",
      "{'나는': 1, '좋다': 5, '오늘': 4, '기분이': 0, '날씨가': 3, '나쁘다': 2}\n",
      "기분이 나는 나쁘다 날씨가 오늘 좋다\n",
      "[[1 1 0 0 1 2]\n",
      " [0 0 0 1 1 1]\n",
      " [1 1 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# 길이를 똑같이 만들고, 의미를 더한다.\n",
    "# 행 : 문장, 열:등장 단어, 값: 문장에 단어가 들어간 갯수\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "print(sentences)\n",
    "vectorizer = CountVectorizer()\n",
    "feat_vac = vectorizer.fit_transform(sentences)\n",
    "print(vectorizer.vocabulary_)\n",
    "print(\"기분이 나는 나쁘다 날씨가 오늘 좋다\")\n",
    "print(feat_vac.toarray())\n",
    "# \"나는 오늘 기분이 좋다\"[1 1 0 0 1 1] -> 기분이 1개 나는1개,오늘 12개,좋다1개\n",
    "# \"오늘 날씨가 좋다\"[0 0 0 1 1 1] => 날씨가 1개, 오늘 1개,좋다 1개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2df9a5",
   "metadata": {},
   "source": [
    "## 2) TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfac3819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 많이 등장한 단어는 중요한 단어일까?\n",
    "# Point: 너무 많이 등장하는 일반적인 단어는 중요도가 낮다라는 것을 반영하는 지표\n",
    "# TF = 특정 문서 d에서 단어 t가 나타나는 빈도 \n",
    "# IDF = 단어가 전체 문서에서 얼마나 희귀한지를 나타내는 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b99f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공식으로 이해하기\n",
    "# tf(d,t) = d번 문장에서 단어 t가 등장한 횟수\n",
    "# df(t) = 전체ㅐ 문장들에ㅐ서 t가 등장한 문장의 수\n",
    "# idf(t) = log(n/(1+df(t)))\n",
    "\n",
    "# 예제\n",
    "# d=0, t=\"기분이\" | 0번째 문장 \"기분이\" 단어\n",
    "# tf(d,t) = 1\n",
    "# df(t) = 2\n",
    "# idf(t) = log(3/2) = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1c33e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 2, '좋다': 7, '오늘': 6, '기분이': 1, '날씨가': 4, '나쁘다': 3, '집에': 8, '가고': 0, '싶다': 5}\n",
      "기분이 나는 나쁘다 날씨가 오늘 좋다\n",
      "[[0.         0.42176004 0.42176004 0.         0.         0.\n",
      "  0.42176004 0.6829022  0.        ]\n",
      " [0.         0.         0.         0.         0.70203482 0.\n",
      "  0.55349232 0.44809973 0.        ]\n",
      " [0.         0.52640543 0.52640543 0.66767854 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.5417361  0.         0.         0.         0.         0.5417361\n",
      "  0.         0.34578314 0.5417361 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# 일반적인 단어보다 중요한 단어에 더 점수를 주겠다\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_vec = vectorizer.fit_transform(sentences)\n",
    "print(vectorizer.vocabulary_)\n",
    "print(\"기분이 나는 나쁘다 날씨가 오늘 좋다\")\n",
    "print(tfidf_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d4cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"나는 좋다 오늘 기분이 좋다\",\n",
    "    \"오늘 날씨가 좋다\",\n",
    "    \"나는 기분이 나쁘다\",\n",
    "    \"집에 가고 싶다 집 좋다\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6c8207",
   "metadata": {},
   "source": [
    "# 3. 유사도 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5fbbdd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.53944923 0.44403355 0.23613607]\n",
      " [0.53944923 1.         0.         0.15494533]\n",
      " [0.44403355 0.         1.         0.        ]\n",
      " [0.23613607 0.15494533 0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 코사인 유사도 계산\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity = cosine_similarity(tfidf_vec)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee767750",
   "metadata": {},
   "source": [
    "# 4. 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a820fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어순, 문맥을 잘 이해할 수 있도록 텍스트를 수치화 하는데 동일한 길이의 벡터로 만든다.(Point:어순, 문맥)\n",
    "# 이때 가지고 있는 모든 문장을 학습시키면서 비슷한 문장은 비슷한 벡터로 수치화 한다.\n",
    "# 학습이 잘 되어있는 모델일수록 새로운 문장이 오더라도 벡터화를 잘 할 수 있다.\n",
    "# OpenAI Embeding 모델(유료) / BGE-m3(무료)를 많이 사용한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pj01-data-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
